{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0dc27a-2bb2-4357-bb75-5cf6ffa982bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import requests\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "#Initialize enttities\n",
    "url='https://web.archive.org/web/20230908091635%20/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "table_attributes =['Name','MC_USD_Billion']\n",
    "db_name = 'Banks.db'\n",
    "table_name = 'Largest_banks'\n",
    "output_path = './Largest_banks_data.csv'\n",
    "log_file = 'code_log.txt'\n",
    "csv_path = './exchange_rate.csv'\n",
    "sql_connection = sqlite3.connect(db_name)\n",
    "query_1=f\"SELECT * FROM {table_name}\"\n",
    "query_2 = f\"SELECT AVG(MC_GBP_Billion) FROM {table_name}\"\n",
    "query_3 = f\"SELECT Name from {table_name} LIMIT 5\"\n",
    "# Code for ETL operations on Country-GDP data\n",
    "\n",
    "def log_progress(message):\n",
    "    ''' This function logs the mentioned message at a given stage of the code execution to a log file. Function returns nothing'''\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(log_file,\"a\") as f: \n",
    "        f.write(timestamp + ',' + message + '\\n') \n",
    "\n",
    "def extract(url, table_attributes):\n",
    "    ''' This function aims to extract the required\n",
    "    information from the website and save it to a data frame. The\n",
    "    function returns the data frame for further processing. '''\n",
    "    # Initialize an empty DataFrame with specified column names\n",
    "    df = pd.DataFrame(columns=table_attributes)\n",
    "    \n",
    "    # Fetch the HTML content of a webpage at the specified URL\n",
    "    html_page = requests.get(url).text\n",
    "    \n",
    "    # Parse the fetched HTML using BeautifulSoup\n",
    "    data = BeautifulSoup(html_page, 'html.parser')\n",
    "    \n",
    "    # Find all 'table' elements within the parsed HTML\n",
    "    tables = data.find_all('table')\n",
    "    \n",
    "    # Extract all rows ('tr' elements) from the first table\n",
    "    rows = tables[0].find_all('tr')\n",
    "\n",
    "    # Iterate over all rows, starting from the second row (skipping the header)\n",
    "    for row in rows[1:]:\n",
    "        # Find all 'td' elements (table data) within the row\n",
    "        col = row.find_all('td')\n",
    "        \n",
    "        # Create a dictionary with data for the DataFrame,\n",
    "        # extracting text from the 2nd and 3rd columns of the table row\n",
    "        data_dict = {\n",
    "            table_attributes[0]: col[1].get_text(strip=True),\n",
    "            table_attributes[1]: col[2].get_text(strip=True)\n",
    "        }\n",
    "        \n",
    "        # Create a DataFrame from the dictionary with a single row\n",
    "        df1 = pd.DataFrame(data_dict, index=[0])\n",
    "        \n",
    "        # Append the new data to the main DataFrame, resetting the index\n",
    "        df = pd.concat([df, df1], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def transform(df, csv_path):\n",
    "    ''' This function accesses the CSV file for exchange rate\n",
    "    information, and adds three columns to the data frame, each\n",
    "    containing the transformed version of Market Cap column to\n",
    "    respective currencies'''\n",
    "    # Convert exchange rate DataFrame to dictionary with the first column as keys and the second as values\n",
    "    exchange_rate_df = pd.read_csv(csv_path)\n",
    "    exchange_rate = exchange_rate_df.set_index('Currency')['Rate'].to_dict()\n",
    "    \n",
    "    #Convert MC_USD_Billion to float\n",
    "    df['MC_USD_Billion']=df['MC_USD_Billion'].astype(float)\n",
    "    \n",
    "    #Create new columns for EUR, GBP and INR currencies\n",
    "    df['MC_GBP_Billion'] = [np.round(x*exchange_rate['GBP'],2) for x in df['MC_USD_Billion']]\n",
    "    df['MC_EUR_Billion'] = [np.round(x*exchange_rate['EUR'],2) for x in df['MC_USD_Billion']]\n",
    "    df['MC_INR_Billion'] = [np.round(x*exchange_rate['INR'],2) for x in df['MC_USD_Billion']]\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_to_csv(df, output_path):\n",
    "    df.to_csv(output_path)\n",
    "    ''' This function saves the final data frame as a CSV file in\n",
    "    the provided path. Function returns nothing.'''\n",
    "\n",
    "def load_to_db(df, sql_connection, table_name):\n",
    "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n",
    "    ''' This function saves the final data frame to a database\n",
    "    table with the provided name. Function returns nothing.'''\n",
    "\n",
    "def run_query(query_statement, sql_connection):\n",
    "    query_output = pd.read_sql(query_statement, sql_connection)\n",
    "    ''' This function runs the query on the database table and\n",
    "    prints the output on the terminal. Function returns nothing. '''\n",
    "\n",
    "''' Here, you define the required entities and call the relevant\n",
    "functions in the correct order to complete the project. Note that this\n",
    "portion is not inside any function.'''\n",
    "\n",
    "# Log the initialization of the ETL process \n",
    "log_progress(\"Preliminaries complete. Initiating ETL process\") \n",
    " \n",
    "# Log the beginning of the Extraction process \n",
    "log_progress(\"Data extraction complete. Initiating Transformation process\") \n",
    "extracted_data = extract(url, table_attributes) \n",
    "\n",
    "# Log the beginning of the Transformation process \n",
    "log_progress(\"Data transformation complete. Initiating Loading process\") \n",
    "transformed_data = transform(extracted_data, csv_path) \n",
    "\n",
    "# Log the beginning of the load to CSV process \n",
    "log_progress(\"Data saved to CSV file\") \n",
    "load_to_csv(transformed_data, output_path) \n",
    "\n",
    "#Initiate sql connection\n",
    "log_progress(\"SQL Connection initiated\") \n",
    "sql_connection = sqlite3.connect(db_name)\n",
    "\n",
    "#Log the beginning of the load to DB process \n",
    "log_progress(\"Data loaded to Database as a table, Executing queries\") \n",
    "load_to_db(transformed_data, sql_connection, table_name)\n",
    "\n",
    "#Log the beginning of the querying process \n",
    "log_progress(\"Process Complete\") \n",
    "run_query(query_1,sql_connection)\n",
    "run_query(query_2,sql_connection)\n",
    "run_query(query_3,sql_connection)\n",
    "\n",
    "#Closing connection\n",
    "log_progress(\"Server Connection closed\") \n",
    "sql_connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
